{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikrishna7783/ML_6th_Sem/blob/main/Lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltfn9BZpqoW8"
      },
      "source": [
        "# Import Play Tennis Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjkK40qSqoW9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "df_tennis = pd.read_csv('PlayTennis.csv')\n",
        "print(\"\\n Given Play Tennis Data Set:\\n\\n\", df_tennis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7ZyyXVpqoW-"
      },
      "outputs": [],
      "source": [
        "#df_tennis.columns[1]\n",
        "df_tennis.keys()[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX0Ln7K9qoW-"
      },
      "source": [
        "# Entropy of the Training Data Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ABTmaRNdqoW-",
        "outputId": "f9e71b7a-5e08-442f-da0b-ab3e7d02097e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_tennis' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e43136efec19>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# The initial entropy of the YES/NO attribute for our dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n  INPUT DATA SET FOR ENTROPY CALCULATION:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_tennis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PlayTennis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtotal_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy_of_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tennis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PlayTennis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_tennis' is not defined"
          ]
        }
      ],
      "source": [
        "#Function to calculate the entropy of probaility of observations\n",
        "# -p*log2*p\n",
        "\n",
        "def entropy(probs):\n",
        "    import math\n",
        "    return sum( [-prob*math.log(prob, 2) for prob in probs] )\n",
        "\n",
        "#Function to calulate the entropy of the given Data Sets/List with respect to target attributes\n",
        "def entropy_of_list(a_list):\n",
        "    #print(\"A-list\",a_list)\n",
        "    from collections import Counter\n",
        "    cnt = Counter(x for x in a_list)   # Counter calculates the propotion of class\n",
        "   # print(\"\\nClasses:\",cnt)\n",
        "    #print(\"No and Yes Classes:\",a_list.name,cnt)\n",
        "    num_instances = len(a_list)*1.0   # = 14\n",
        "    print(\"\\n Number of Instances of the Current Sub Class is {0}:\".format(num_instances ))\n",
        "    probs = [x / num_instances for x in cnt.values()]  # x means no of YES/NO\n",
        "    print(\"\\n Classes:\",min(cnt),max(cnt))\n",
        "    print(\" \\n Probabilities of Class {0} is {1}:\".format(min(cnt),min(probs)))\n",
        "    print(\" \\n Probabilities of Class {0} is {1}:\".format(max(cnt),max(probs)))\n",
        "    return entropy(probs) # Call Entropy :\n",
        "\n",
        "# The initial entropy of the YES/NO attribute for our dataset.\n",
        "print(\"\\n  INPUT DATA SET FOR ENTROPY CALCULATION:\\n\", df_tennis['PlayTennis'])\n",
        "\n",
        "total_entropy = entropy_of_list(df_tennis['PlayTennis'])\n",
        "\n",
        "print(\"\\n Total Entropy of PlayTennis Data Set:\",total_entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWG6W9_PqoW-"
      },
      "source": [
        "# Information Gain of Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEqaxYDIqoW-"
      },
      "outputs": [],
      "source": [
        "def information_gain(df, split_attribute_name, target_attribute_name, trace=0):\n",
        "    print(\"Information Gain Calculation of \",split_attribute_name)\n",
        "    '''\n",
        "    Takes a DataFrame of attributes, and quantifies the entropy of a target\n",
        "    attribute after performing a split along the values of another attribute.\n",
        "    '''\n",
        "    # Split Data by Possible Vals of Attribute:\n",
        "    df_split = df.groupby(split_attribute_name)\n",
        "   # for name,group in df_split:\n",
        "    #    print(\"Name:\\n\",name)\n",
        "     #   print(\"Group:\\n\",group)\n",
        "\n",
        "    # Calculate Entropy for Target Attribute, as well as\n",
        "    # Proportion of Obs in Each Data-Split\n",
        "    nobs = len(df.index) * 1.0\n",
        "   # print(\"NOBS\",nobs)\n",
        "    df_agg_ent = df_split.agg({target_attribute_name : [entropy_of_list, lambda x: len(x)/nobs] })[target_attribute_name]\n",
        "    #print([target_attribute_name])\n",
        "    #print(\" Entropy List \",entropy_of_list)\n",
        "    #print(\"DFAGGENT\",df_agg_ent)\n",
        "    df_agg_ent.columns = ['Entropy', 'PropObservations']\n",
        "    #if trace: # helps understand what fxn is doing:\n",
        "     #   print(df_agg_ent)\n",
        "\n",
        "    # Calculate Information Gain:\n",
        "    new_entropy = sum( df_agg_ent['Entropy'] * df_agg_ent['PropObservations'] )\n",
        "    old_entropy = entropy_of_list(df[target_attribute_name])\n",
        "    return old_entropy - new_entropy\n",
        "\n",
        "\n",
        "print('Info-gain for Outlook is :'+str( information_gain(df_tennis, 'Outlook', 'PlayTennis')),\"\\n\")\n",
        "print('\\n Info-gain for Humidity is: ' + str( information_gain(df_tennis, 'Humidity', 'PlayTennis')),\"\\n\")\n",
        "print('\\n Info-gain for Wind is:' + str( information_gain(df_tennis, 'Wind', 'PlayTennis')),\"\\n\")\n",
        "print('\\n Info-gain for Temperature is:' + str( information_gain(df_tennis, 'Temperature','PlayTennis')),\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy51CyFnqoW-"
      },
      "source": [
        "# ID3 Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8c9IOWxqoW_"
      },
      "outputs": [],
      "source": [
        "def id3(df, target_attribute_name, attribute_names, default_class=None):\n",
        "\n",
        "    ## Tally target attribute:\n",
        "    from collections import Counter\n",
        "    cnt = Counter(x for x in df[target_attribute_name])# class of YES /NO\n",
        "\n",
        "    ## First check: Is this split of the dataset homogeneous?\n",
        "    if len(cnt) == 1:\n",
        "        return next(iter(cnt))  # next input data set, or raises StopIteration when EOF is hit.\n",
        "\n",
        "    ## Second check: Is this split of the dataset empty?\n",
        "    # if yes, return a default value\n",
        "    elif df.empty or (not attribute_names):\n",
        "        return default_class  # Return None for Empty Data Set\n",
        "\n",
        "    ## Otherwise: This dataset is ready to be devied up!\n",
        "    else:\n",
        "        # Get Default Value for next recursive call of this function:\n",
        "        default_class = max(cnt.keys()) #No of YES and NO Class\n",
        "        # Compute the Information Gain of the attributes:\n",
        "        gainz = [information_gain(df, attr, target_attribute_name) for attr in attribute_names] #\n",
        "        index_of_max = gainz.index(max(gainz)) # Index of Best Attribute\n",
        "        # Choose Best Attribute to split on:\n",
        "        best_attr = attribute_names[index_of_max]\n",
        "\n",
        "        # Create an empty tree, to be populated in a moment\n",
        "        tree = {best_attr:{}} # Iniiate the tree with best attribute as a node\n",
        "        remaining_attribute_names = [i for i in attribute_names if i != best_attr]\n",
        "\n",
        "        # Split dataset\n",
        "        # On each split, recursively call this algorithm.\n",
        "        # populate the empty tree with subtrees, which\n",
        "        # are the result of the recursive call\n",
        "        for attr_val, data_subset in df.groupby(best_attr):\n",
        "            subtree = id3(data_subset,\n",
        "                        target_attribute_name,\n",
        "                        remaining_attribute_names,\n",
        "                        default_class)\n",
        "            tree[best_attr][attr_val] = subtree\n",
        "        return tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HjN3XQCqoW_"
      },
      "source": [
        "# Predicting Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia33S3Z_qoW_"
      },
      "outputs": [],
      "source": [
        "# Get Predictor Names (all but 'class')\n",
        "attribute_names = list(df_tennis.columns)\n",
        "print(\"List of Attributes:\", attribute_names)\n",
        "attribute_names.remove('PlayTennis') #Remove the class attribute\n",
        "print(\"Predicting Attributes:\", attribute_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBEvsyvjqoW_"
      },
      "outputs": [],
      "source": [
        "# Tree Construction\n",
        "# Run Algorithm:\n",
        "from pprint import pprint\n",
        "tree = id3(df_tennis,'PlayTennis',attribute_names)\n",
        "print(\"\\n\\nThe Resultant Decision Tree is :\\n\")\n",
        "#print(tree)\n",
        "pprint(tree)\n",
        "attribute = next(iter(tree))\n",
        "print(\"Best Attribute :\\n\",attribute)\n",
        "print(\"Tree Keys:\\n\",tree[attribute].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzJ4rhqPqoW_"
      },
      "source": [
        "# Classification Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqmCd4ZdqoW_"
      },
      "outputs": [],
      "source": [
        "def classify(instance, tree, default=None): # Instance of Play Tennis with Predicted\n",
        "\n",
        "    #print(\"Instance:\",instance)\n",
        "    attribute = next(iter(tree)) # Outlook/Humidity/Wind\n",
        "    print(\"Key:\",tree.keys())  # [Outlook,Humidity,Wind ]\n",
        "    print(\"Attribute:\",attribute) # [Key /Attribute Both are same ]\n",
        "\n",
        "    # print(\"Insance of Attribute :\",instance[attribute],attribute)\n",
        "    if instance[attribute] in tree[attribute].keys(): # Value of the attributs in  set of Tree keys\n",
        "        result = tree[attribute][instance[attribute]]\n",
        "        print(\"Instance Attribute:\",instance[attribute],\"TreeKeys :\",tree[attribute].keys())\n",
        "        if isinstance(result, dict): # this is a tree, delve deeper\n",
        "            return classify(instance, result)\n",
        "        else:\n",
        "            return result # this is a label\n",
        "    else:\n",
        "        return default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_bjywlGqoW_"
      },
      "outputs": [],
      "source": [
        "df_tennis['predicted'] = df_tennis.apply(classify, axis=1, args=(tree,'No') )\n",
        "    # classify func allows for a default arg: when tree doesn't have answer for a particular\n",
        "    # combitation of attribute-values, we can use 'no' as the default guess\n",
        "\n",
        "print(df_tennis['predicted'])\n",
        "\n",
        "print('\\n Accuracy is:\\n' + str( sum(df_tennis['PlayTennis']==df_tennis['predicted'] ) / (1.0*len(df_tennis.index)) ))\n",
        "\n",
        "\n",
        "df_tennis[['PlayTennis', 'predicted']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "aJgCMKBPqoW_"
      },
      "source": [
        "# Classification Accuracy: Training/Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "MlYJ7jwpqoW_"
      },
      "outputs": [],
      "source": [
        "training_data = df_tennis.iloc[1:-4] # all but last four instances\n",
        "test_data  = df_tennis.iloc[-4:] # just the last four\n",
        "train_tree = id3(training_data, 'PlayTennis', attribute_names)\n",
        "\n",
        "test_data['predicted2'] = test_data.apply(classify,axis=1,args=(train_tree,'Yes'))\n",
        "\n",
        "print ('\\n\\n Accuracy is : ' + str( sum(test_data['PlayTennis']==test_data['predicted2'] ) / (1.0*len(test_data.index)) ))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}